@* DmChat.razor - DM-to-LLM chat interface using Flowbite Chat components *@
@* Non-streaming implementation aligned with Flowbite Blazor AI Chat patterns *@
@using Riddle.Web.Services
@inject IRiddleLlmService LlmService
@inject ILogger<DmChat> Logger

<div class="flex flex-col h-full min-h-0">
    <Conversation>
        <ConversationContent AutoScrollBehavior="ConversationAutoScrollBehavior.StickToBottom" Class="px-2 py-4">
            @if (!_messages.Any())
            {
                <div class="flex flex-col items-center justify-center h-48 text-center">
                    <BookOpenIcon Class="w-12 h-12 text-purple-500 dark:text-purple-400 mb-3" />
                    <h3 class="text-lg font-semibold text-gray-900 dark:text-white mb-1">Ready to Begin</h3>
                    <p class="text-sm text-gray-500 dark:text-gray-400 max-w-sm">
                        Describe a player action, ask for narrative guidance, or request a rules clarification.
                    </p>
                </div>
            }
            else
            {
                @foreach (var message in _messages)
                {
                    <ChatMessage @key="message.Id"
                                 From="@message.Role"
                                 AvatarInitials="@(message.Role == ChatMessageRole.User ? "DM" : "R")">
                        <ChatMessageContent Variant="@(message.Role == ChatMessageRole.User ? ChatMessageVariant.Contained : ChatMessageVariant.Flat)">
                            @if (!string.IsNullOrEmpty(message.Reasoning))
                            {
                                <Reasoning DefaultOpen="false">
                                    <ReasoningTrigger />
                                    <ReasoningContent Text="@message.Reasoning" />
                                </Reasoning>
                            }
                            <ChatResponse Text="@message.Content" Role="@message.Role" />
                        </ChatMessageContent>
                        
                        @if (message.Role == ChatMessageRole.Assistant)
                        {
                            <ChatActions Class="justify-start -ml-3">
                                <ChatAction Tooltip="Copy" OnClick="@(() => CopyMessageAsync(message.Content))">
                                    <FileCopyAltIcon Class="h-4 w-4" aria-hidden="true" />
                                </ChatAction>
                                @if (message.TotalTokens.HasValue)
                                {
                                    <span class="text-xs text-gray-400 dark:text-gray-500 ml-2">
                                        @message.TotalTokens.Value.ToString("N0") tokens
                                    </span>
                                }
                            </ChatActions>
                        }
                    </ChatMessage>
                }
            }

            @if (_isBusy)
            {
                <div class="flex items-center gap-2 px-4 pb-4 text-sm text-gray-500 dark:text-gray-400">
                    <Loader />
                    <span>@_busyLabel</span>
                </div>
            }
        </ConversationContent>

        <ConversationScrollButton />
    </Conversation>

    <PromptInput OnSubmit="HandleSubmitAsync"
                 Text="@(_inputText ?? string.Empty)"
                 TextChanged="HandleTextChanged">
        <PromptInputBody>
            <PromptInputTextarea Placeholder="Describe the action or ask Riddle for advice..." />
        </PromptInputBody>
        <PromptInputFooter Class="flex items-center justify-between">
            <span class="text-xs text-gray-400 dark:text-gray-500">
                Press Enter to send
            </span>
            <PromptInputSubmit Status="@_submissionStatus"
                               Disabled="@(string.IsNullOrWhiteSpace(_inputText) || _isBusy)"
                               Label=""
                               SubmittingLabel=""
                               StreamingLabel=""
                               ErrorLabel="" />
        </PromptInputFooter>
    </PromptInput>
</div>

@code {
    [Parameter]
    public Guid CampaignId { get; set; }

    [Inject]
    private IJSRuntime JSRuntime { get; set; } = default!;

    private List<DmChatMessage> _messages = new();
    private string _inputText = string.Empty;
    private bool _isBusy;
    private string _busyLabel = "Riddle is thinking...";
    private PromptSubmissionStatus _submissionStatus = PromptSubmissionStatus.Idle;

    private Task HandleTextChanged(string value)
    {
        _inputText = value;
        return Task.CompletedTask;
    }

    private async Task HandleSubmitAsync(PromptInputMessage prompt)
    {
        var userText = prompt.Text?.Trim();
        if (string.IsNullOrWhiteSpace(userText))
            return;

        if (_isBusy)
            return;

        // Add user message
        var userMessage = new DmChatMessage(
            Id: Guid.NewGuid(),
            Role: ChatMessageRole.User,
            Content: userText
        );
        _messages.Add(userMessage);

        // Set busy state and clear input (like ChatAiPage does)
        _isBusy = true;
        _busyLabel = "Riddle is thinking...";
        _submissionStatus = PromptSubmissionStatus.Submitting;
        _inputText = string.Empty;
        await InvokeAsync(StateHasChanged);

        try
        {
            // Non-streaming: Get full response
            var response = await LlmService.ProcessDmInputAsync(CampaignId, userText);

            if (response.IsSuccess)
            {
                var assistantMessage = new DmChatMessage(
                    Id: Guid.NewGuid(),
                    Role: ChatMessageRole.Assistant,
                    Content: response.Content,
                    Reasoning: response.Reasoning,
                    PromptTokens: response.PromptTokens,
                    CompletionTokens: response.CompletionTokens,
                    TotalTokens: response.TotalTokens,
                    ToolCallCount: response.ToolCallCount,
                    DurationMs: response.DurationMs
                );
                _messages.Add(assistantMessage);
            }
            else
            {
                // Error response
                var errorMessage = new DmChatMessage(
                    Id: Guid.NewGuid(),
                    Role: ChatMessageRole.Assistant,
                    Content: $"**Error:** {response.ErrorMessage}\n\nPlease check your API configuration and try again."
                );
                _messages.Add(errorMessage);
                _submissionStatus = PromptSubmissionStatus.Error;
            }
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error processing DM input");
            
            var errorMessage = new DmChatMessage(
                Id: Guid.NewGuid(),
                Role: ChatMessageRole.Assistant,
                Content: $"**Error:** {ex.Message}\n\nPlease check your API configuration and try again."
            );
            _messages.Add(errorMessage);
            _submissionStatus = PromptSubmissionStatus.Error;
        }
        finally
        {
            _isBusy = false;
            if (_submissionStatus != PromptSubmissionStatus.Error)
            {
                _submissionStatus = PromptSubmissionStatus.Idle;
            }
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task CopyMessageAsync(string content)
    {
        if (string.IsNullOrWhiteSpace(content))
            return;

        try
        {
            await JSRuntime.InvokeVoidAsync("navigator.clipboard.writeText", content);
        }
        catch
        {
            // Clipboard may not be available
        }
    }

    private sealed record DmChatMessage(
        Guid Id,
        ChatMessageRole Role,
        string Content,
        string? Reasoning = null,
        int? PromptTokens = null,
        int? CompletionTokens = null,
        int? TotalTokens = null,
        int ToolCallCount = 0,
        long? DurationMs = null);
}
